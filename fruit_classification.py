# -*- coding: utf-8 -*-
"""Fruit Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cwclBo7nJBryebE_fpih1wGnS3G72BpR

### **Importing libraries and setup**
"""

import tensorflow as tf
from tensorflow import keras  
from tensorflow.keras import layers 
import numpy as np
from keras.utils import np_utils
from keras.preprocessing.image import array_to_img, img_to_array, load_img

"""### ***Import Dataet either loading raw dataset or by downloading***"""

from google.colab import drive
drive.mount('/content/drive')

"""### **Loadind dataset from drive**"""

!unzip -q '/content/drive/MyDrive/Dataset/Fruits_Dataset.v1-resize-512x512-reflect.folder.zip'

"""### **Checking Classes**"""

!ls train

"""### **Creatind database by dividing the data into validation and training dataset**"""

image_size = (512, 512)
batch_size = 8

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/train",
    label_mode='categorical',
    validation_split=0.2,
    subset="training",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/train",
    label_mode='categorical',
    validation_split=0.2,
    subset="validation",
    seed=1337,
    image_size=image_size,
    batch_size=batch_size,
)

"""### **Viualization of Dataset**"""

import matplotlib.pyplot as plt
plt.figure(figsize=(10,10))
for images, label in train_ds.take(1):
 for i in range(8):
  ax= plt.subplot(2,4,i+1)
  plt.imshow(images[i].numpy().astype("uint8"))
  plt.axis("off")

"""### **Data augmentation**"""

data_augmen = keras.Sequential(
   [
    layers.experimental.preprocessing.RandomFlip("horizontal"),
    layers.experimental.preprocessing.RandomRotation(0.1),
   ] 
)

"""### **Viualization of Data augmeatation of database**"""

plt.figure(figsize=(10,10))
for image, label in train_ds.take(1):
  for i in range(20):
    aug_images=data_augmen(images)
    ax=plt.subplot(4,5,i+1)
    plt.imshow(aug_images[2].numpy().astype("uint8"))

"""### **Configure dataset performance**"""

train_ds = train_ds.prefetch(buffer_size=32)
val_ds = val_ds.prefetch(buffer_size=32)

"""### **Building a model**"""

def make_model(input_shape,num_classes):
  inputs=keras.Input(shape=input_shape)
  x=data_augmen(inputs)
  x=layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)
  x=layers.Conv2D(32,3,strides=2,padding="same")(x)
  x=layers.BatchNormalization()(x)
  x=layers.Activation("relu")(x)

  x=layers.Conv2D(64,3,padding="same")(x)
  x=layers.BatchNormalization()(x)
  x=layers.Activation("relu")(x)

  prev_blk_residual=x

  for size in [128, 256, 512, 728]:

      x=layers.Activation("relu")(x)
      x=layers.SeparableConv2D(size,3,padding="same")(x)
      x=layers.BatchNormalization()(x)

      x=layers.Activation("relu")(x)
      x=layers.SeparableConv2D(size,3,padding="same")(x)
      x=layers.BatchNormalization()(x)

      x=layers.MaxPooling2D(3,strides=2,padding="same")(x)


      res=layers.Conv2D(size,3,strides=2,padding="same")(prev_blk_residual)

      x=layers.add([x,res])
      prev_blk_residual=x

      x=layers.SeparableConv2D(1024,3,padding="same")(x)
      x=layers.BatchNormalization()(x)
      x=layers.Activation("relu")(x)

      x=layers.GlobalAveragePooling2D()(x)

      if num_classes == 2:
          activation="sigmoid"
          units=1;
      else:
          activation="softmax"
          units=num_classes

      x=layers.Dropout(0.5)(x)
      outputs=layers.Dense(units,activation=activation)(x)
      return keras.Model(inputs,outputs)
      
model=make_model(input_shape=image_size+(3,),num_classes=6)
keras.utils.plot_model(model,show_shapes=True)

"""### **Training of Model**"""

epochs=5

callbacks=[
           keras.callbacks.ModelCheckpoint("save_at_{epoch}.h5"),
]

model.compile(
            optimizer=keras.optimizers.Adam(1e-3),
            loss="categorical_crossentropy",
            metrics=["accuracy"],
)
model.fit(
    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,
)

from keras.models import load_model
model.save('/content/drive/MyDrive/Dataset/Fruits_Dataset.v1-resize-512x512-reflect.folder/my_model.h5')  # creates a HDF5 file 'my_model.h5'

"""### **Printing and testing of random images**"""

img = keras.preprocessing.image.load_img(
    "/content/drive/MyDrive/Dataset/Fruits_Dataset.v1-resize-512x512-reflect.folder/Test_images/Cherry Tamto.jpg", target_size=image_size
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)  # Create batch axis

predictions = model.predict(img_array)
score = predictions[0]
np.shape(score)
print("Tomat3: %.3f and Tomat4: %.3f and Cherry Tomato: %.3f and Maroon Tomato: %.3f and Yellow Tomato: %.3f and walnut: %.3f" % (score[0],score[1],score[2],score[3],score[4],score[5]))